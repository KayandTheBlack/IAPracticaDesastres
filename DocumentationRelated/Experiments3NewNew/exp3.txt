Experimento 3

PLAN

Conocimientos previos: hay que tener en cuenta la función de energía y la de la probabilidad de aceptar estados peores, así como el comportamiento de Simulated Annealing.
Objetivo: Optimizar SA (parámetros: steps, stiter, k y lambda), partiendo del escenario y condiciones de los experimentos anteriores, esto es, 100 grupos, 5 centros, 1 helcóptero por centro, los operadores mov, swap y switch sin restricciones y el método de inicialización 0.
Observación: Puede haber parámetros que consigan un coste mucho menor. En particular, hay que tener en cuenta que k y lambda influyen en la función de energía y la probabilidad de aceptar un estado peor, se intuye que dependiendo de la heurística podrían ser mejores unos valores o otros; steps y stiter determinan las iteraciones y su distribución, se intuye que la función va a tender a ser mejor como más steps tenga y que la influencia de stiter dependerá de los parámetros k y lambda.
Hipótesis: Los parámetros son indiferentes (H0) o influyen decisivamente.
Método:
	- Seguiremos el ejemplo del enunciado adaptándolo a las circunstancias de nuestro problema.
	- Dada la complejidad del espacio de la función (4 variables), empezaremos con k y lambda, ya que el número de iteraciones (steps y stiter) dependerán de estos parámetros. La importancia de stiter depende de los valores de estos parámetros.
	- Fijaremos, pues, unos valores determinados de steps y stiter. Steps deberá ser suficientemente grande para que haya convergencia. El valor por defecto de la clase es 10000, y es el usado en el ejemplo. Lo que haremos nosotros será realizar un paso previo, que será hacer ejecuciones con distintos valores de steps, stiter = 100 ((ver explicación a continuación), y los valores por defecto de k (20) y lambda (0.005), para comprobar que haya suficientes iteraciones para converger. En este paso previo también ejecutaremos HC para los mismos casos, como referencia. El método de ejecución será el mismo que en los otros pasos y está explicado posteriormente. Fijaremos así el steps incial, pero igualmente es arbitrario y volveremos a steps cuando lo optimicemos al final. Stiter será arbitrario al principio, fijaremos el valor de 100 (el usado por defecto en la clase de Simulated Annealing y divisor de steps).
	- Dada la dificultad de realizar una búsqueda exhaustiva, probaremos una serie de valores distintos considerados extremos (siguiendo la guía) para k y lambda, calcularemos las medias, observaremos el gráfico 3D resultante (de nuevo, como en la guía) y tendremos una idea de hacia donde se minimiza la función. Concretamente, el gráfico nos mostrará los costes en tiempo según los distintos valores de k y lambda.
	- Volveremos a repetir acotando los valores a la parte donde se minimice el coste, y tendremos en cuenta los resultados en caso de que sean significativos (esto es, las medias sean suficientemente diferenciadas).
	- Teniendo en cuenta lo que tarda en converger y la forma del gráfico (si observamos que para un solo parámetro determinado la solución es buena, por ejemplo), será indicado fijar uno de los dos parámetros y ver cómo varía la función variando el otro.
	- Las ejecuciones se harán del siguiente modo:
		- Elegiremos 10 semillas aleatorias, una para cada réplica.
		- Haremos 3 repeticiones de cada ejecución para una misma semilla, porque al ser un método estocástico hay una cierta variabilidad (pero pequeña). Podríamos haber hecho más repeticiones, pero la variabilidad es pequeña y además el coste en tiempo de ejecución es considerable, porque hay muchas iteraciones de SA.
	- Guardaremos los parámetros k y lambda usados en la réplica, el coste en tiempo (de la heurística), y el tiempo de ejecución. La métrica para medir cómo de buena es una solución será en todo momento su coste en tiempo (de la heurística).
	- Generaremos una tabla con las medias de las distintas semillas para cada par de valores k y lambda.
	- La gráfica 3D se dibujará partiendo de la tabla anterior.
	- Una vez hayamos escogido k y lambda, optimizaremos stiter utlizando el mismo método que antes (parámetros fijados, 10 semillas, 3 repeticiones...), aunque esta vez nos moveremos en una única dimensión. Es posible que sea poco importante (como explica el enunciado). Lo comprobaremos con el gráfico en 2 dimensiones y la tabla.
	- Finalmente, optimizaremos steps. La función irá subiendo y bajando, al principio mucho y al final poco, pero no va a tener sentido poner un nombre de iteraciones absurdamente grande para conseguir mejores de una unidad, por ejemplo. Habiendo fijado los demás tres parámetros, variaremos valores "razonables" de steps y comparemos con la ejecución de HC (que también guardaremos, esta vez), como referencia.


EJECUCIÓN

-Ejecutamos hasta 5 versiones de la función experiment3_prevSteps, con distintos rangos de steps (entre 5k y 2M). Llegamos a la conclusión, observando las tablas de medias y las gráficas de que 20k será un número suficientemente grande para que haya convergencia (a partir de 20k prácticamente no varía y en cambio aumenta el tiempo de ejecución) en los experimentos (volveremos a steps una vez tengamos k, lambda y stiter).
-Procedemos a ejecutar la función experiment3_lambdaK2(), con steps ya en 20k. Primera versión: valores extremos de lambdas[] = {1,0.01,0.0001}; ks[] = {1,5,25,125}, los usados en el ejemplo. Observando el gráfico 3D de medias detectamos un mínimo en k = 5, lambda = 0.0001. Cabe destacar que las diferencias en el gráfico son muy significativas (el máximo es 3622.81, el mínimo es 2582.56). Para todo lambda = 1 parece haber malas soluciones. Con 0.01 obtenemos buenso resultados y a medida que va aumentando k parece ir minimizándose lentamente. Sin embargo, alrededor de lambda = 0.0001 y k = 5 parece haber un mínimo.
-Repetiremos el procedimiento anterior acotando valores alrededor del último caso, tal y como sugiere el enunciado: lambdas[] = {0.001, 0.0001,0.00001}; ks[] = {1,5,10,15}. Notamos que aún hay cierta variabilidad (rango de 500 aprox), pero menos antes, la desviación estándar se ha reducido. Curiosamente, el mínimo de esta ejecución es exactamente el mismo que antes: k = 5, lambda = 0.001. No nos parece oportuno continuar acotando porque las diferencias cada vez son menores y el mínimo encontrado parece ser un buen valor.
-Así, pues, ya tenemos que k = 5 y lambda = 0.0001. Ahora procederemos a realizar las ejecuciones (experiment3_stiter2) con distintos stiters (todos ellos divisores de steps): 50,80,100,125,160,200,250,400,500,625,800,1000,1250. Como ya advertía la guía, podría pasar que dependiendo de los parámetros k y lambda escogidos stiter fuera poco relevante. De hecho, nos es imposible detectar ninguna tendencia, las medias dan valores muy parecidos. Para una media de 2407.67, la desviación estándar es de apenas 2.46. El coeficiente de correlación es r = 0.14. No tiene sentido graficar. El mínimo es 160, así que vamos a coger este valor, aunque perfectamente nos podríamos haber quedado con el 100 porque la diferencia es del orden de unidades. Lo que pasa es que para probar los nuevos steps habrá que ir con cuidado de que sean divisibles por 160.
-Finalmente, volvemos a steps. Esencialmente repetiremos el paso previo, con SA y HC, para asegurarnos de que converja correctamente y sea mejor que HC con los nuevos valores. También unción experiment3_prevSteps, fijando los parámetros ya determinados y con posibles valores de steps de {5120,10400,20000,30400,40000}. Observando la tabla de medias y su correspondiente gráfica, notamos que en 5120 y 10400 steps de SA HC sigue siendo mejor, pero de 20k para adelante no hay duda alguna de que SA se comporta mejor. Además observamos que SA se va estabilizando. De 30400 a 40000 varia del orden de... menos de una unidad! Concretamente, alrededor de 3 décimas. De 20k a 30400 el cambio es de alrededor de 11 unidades. Vamos a hacer una última ejecución con steps enormes para asegurarnos. Cabe decir que, aunque no se pida en este experimento concreto, el factor tiempo de ejecución es siempre una limitación a tener en mente para poder ejecutar los experimentos y que no va a tener sentido hacer un número gigantesco de pasos para ganar una unidad. Añadiremos 80000,160000. En esta última ejecución, observamos en la tabla de medias y en el gráfico que efectivamente SA se ha estabilizado, como en el enunciado, y que ya solo se mueve por el orden de les unidades. Esta vez, de 30400 a 1600000 solo mejora 4 unidades, por lo que podríamos coger el valor de 160000, pero es prácticamente el mismo con más tiempo de ejecución.

CONCLUSIÓN

Experimentalmente hemos optimizado la función de búsqueda de SA a los parámetros steps = 30400, stiter = 160, k = 5 y lambda = 0.0001. Incrementado mucho steps parece que solo conseguiríamos mejorar la función del orden de las unidades.